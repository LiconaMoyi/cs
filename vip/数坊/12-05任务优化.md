### P0P1任务运行超1小时

<img title="" src="file:///D:/Users/moyi.li/AppData/Roaming/marktext/images/2023-12-05-10-34-37-image.png" alt="" width="829">

##### 1.277940

任务描述：466收退货报表，会与468，576，676等共同用于库存对账

结论：466收退货任务历史期间的数据不会改动，只需要跑当月期间数据后合并历史期间数据即可

###### 1.1.466收退货任务，分析如下：

**1.1.PO前置关联**

下述片段存在的问题：PO行表17亿左右，PO头五百万左右，VPS表15亿左右，且对于收退货业务来说，一旦有收退货流水进入当月期间，那么po行表一定会发生更新，可对po行表先按更新时间进行过滤

![](D:\Users\moyi.li\AppData\Roaming\marktext\images\2023-12-07-14-06-09-image.png)

验证：

```sql
--- 分析收退货PO最小创建和日期，看是否能够缩减关联po行的数据
select min(b.create_time),a.month from (select * from vipfin.fin_fcs2_po_rcv_transaction where month>='202201') a
left join (select * from temp_fin.cux_po_lines_detail )b
on a.po_no=b.po_no
and UPPER(a.item_no)=UPPER(b.item_no) group by a.month
```

*po行最小创建日期，更新日期如下*

| min(create_time)        | min(update_time)        | count     | month  |
| ----------------------- | ----------------------- | --------- | ------ |
| 2018-01-02 18:25:43.000 | 2022-01-02 11:32:08.000 | 106936399 | 202201 |
| 2018-01-02 18:25:43.000 | 2022-02-02 15:17:38.000 | 69549976  | 202202 |
| 2017-10-26 23:48:33.000 | 2022-03-02 10:17:57.000 | 95048174  | 202203 |
| 2017-05-16 09:54:31.000 | 2022-04-02 10:20:50.000 | 92142979  | 202204 |
| 2017-10-31 16:13:54.000 | 2022-05-02 13:00:43.000 | 110865719 | 202205 |
| 2015-01-16 18:18:11.000 | 2022-06-02 11:12:18.000 | 128229765 | 202206 |
| 2016-03-28 17:29:15.000 | 2022-07-02 11:24:11.000 | 96618259  | 202207 |
| 2017-08-16 14:42:18.000 | 2022-08-02 13:03:24.000 | 92094258  | 202208 |
| 2018-01-02 18:25:43.000 | 2022-09-02 13:07:18.000 | 97658399  | 202209 |
| 2018-01-02 18:25:43.000 | 2022-10-02 12:28:38.000 | 124342277 | 202210 |
| 2018-01-02 18:25:43.000 | 2022-11-02 10:50:46.000 | 132894680 | 202211 |
| 2018-01-02 18:30:30.000 | 2022-12-02 09:52:02.000 | 129841072 | 202212 |
| 2018-01-02 18:25:43.000 | 2023-01-02 11:07:58.000 | 103675381 | 202301 |
| 2018-01-05 16:41:41.000 | 2023-02-02 10:07:13.000 | 93565889  | 202302 |
| 2018-03-20 20:30:27.000 | 2023-03-02 10:16:32.000 | 127700147 | 202303 |
| 2018-03-22 14:02:02.000 | 2023-04-02 10:32:44.000 | 135284699 | 202304 |
| 2018-04-09 12:13:32.000 | 2023-05-02 10:42:12.000 | 138447537 | 202305 |
| 2018-04-09 12:13:32.000 | 2023-06-02 09:42:04.000 | 147310216 | 202306 |
| 2018-03-25 09:54:22.000 | 2023-07-02 10:27:18.000 | 112747201 | 202307 |
| 2018-04-09 12:13:32.000 | 2023-08-02 09:59:53.000 | 105864500 | 202308 |
| 2018-01-02 18:30:30.000 | 2023-09-02 09:49:42.000 | 112886449 | 202309 |
| 2018-04-09 12:13:32.000 | 2023-10-02 11:53:48.000 | 133791171 | 202310 |
| 2018-04-09 12:13:32.000 | 2023-11-02 09:15:04.000 | 176113352 | 202311 |
| 2018-04-09 12:13:32.000 | 2023-12-02 10:17:36.000 | 33878339  | 202312 |

RETURN和RECEIVE指令数据在处理时候必定会更新PO行

![](D:\Users\moyi.li\AppData\Roaming\marktext\images\2023-12-07-17-45-25-image.png)

![](D:\Users\moyi.li\AppData\Roaming\marktext\images\2023-12-07-17-47-56-image.png)

改造后如下：

po行表当月1200w左右，一月预估在5kw左右，过滤行表后关联PO头表再关联VIS![](D:\Users\moyi.li\AppData\Roaming\marktext\images\2023-12-07-14-13-46-image.png)

**1.2.在收退货表关联PO表**

收退货表按transaction_date对数据进行切分，历史的期间的数据不动，只重跑当月期间的数据

![](D:\Users\moyi.li\AppData\Roaming\marktext\images\2023-12-07-14-21-23-image.png)

**1.3.设置互不影响任务并发运行**

![](D:\Users\moyi.li\AppData\Roaming\marktext\images\2023-12-07-14-22-41-image.png)

**1.4.合并当月与历史期间数据**

```sql
insert overwrite table vipfin.ads_rcv_transaction_bill_new partition(month)
select XXX
-- 历史期间数据
from vipfin.ads_rcv_transaction_bill_new where month=DATE_FORMAT(add_months(current_date,-1),'yyyy-MM')
union all
select
XXX
-- 当月重跑出来的数据
from temp_fin.rcv_transaction_bill_report_current
```

**1.5.spark参数配置**

**set spark.sql.shuffle.partitions=3200;**

为什么要设置3200？200（-max_executor_num=200） * 4（-executor-cores=4） * 2~3

![](D:\Users\moyi.li\AppData\Roaming\marktext\images\2023-12-07-14-39-20-image.png)

并行度个数判断：将shuffle的大小控制在100-500MB

如果shuffle map task的数据量都很小，可以将并行度往小调整。

![](D:\Users\moyi.li\AppData\Roaming\marktext\images\2023-12-07-16-28-53-image.png)

**将小表改为视图**

**-executor-memory=10g**

该参数用于设置每个Executor进程的内存。Executor内存的大小，很多时候直接决定了Spark作业的性能，而且跟常见的JVM OOM异常，也有直接的关联

**-hiveconf mapreduce.input.fileinputformat.split.maxsize=67108864,-hiveconf mapreduce.input.fileinputformat.split.minsize=67108864**

input 过高时，可以采用增加分片的方式：现在默认分片是256M
**大文件拆分**
set spark.sql.files.maxPartitionBytes=33554432; --大文件拆分 32M

**去除小文件合并**
set spark.sql.merge.output.enabled=false;

参考文档：

https://wiki.corp.vipshop.com/pages/viewpage.action?pageId=330106182

[Configuration - Spark 3.2.0 Documentation](https://spark.apache.org/docs/3.2.0/configuration.html#spark-sql)

**1.6.验数**

数据量验证：

![](D:\Users\moyi.li\AppData\Roaming\marktext\images\2023-12-07-15-14-22-image.png)

一致性校验：

抽样对比无误！
